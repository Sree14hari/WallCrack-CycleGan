{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95eda222",
   "metadata": {},
   "source": [
    "Code to Analyse width of Cracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d5d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Dataset_1000: 100%|██████████| 1000/1000 [00:08<00:00, 113.55it/s]\n",
      "Analyzing shadow: 100%|██████████| 1000/1000 [00:11<00:00, 83.81it/s]\n",
      "Analyzing unshadowed_results:  61%|██████▏   | 613/1000 [00:05<00:03, 112.06it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================================================\n",
    "# ================= 1. CORE FUNCTIONS ===========================\n",
    "# ===============================================================\n",
    "\n",
    "def crack_width_measure(binary_image, pixel_size_mm=0.1):\n",
    "    \"\"\"Measures the maximum crack width from a binary image.\"\"\"\n",
    "    if np.sum(binary_image) == 0: return 0\n",
    "    skeleton = skeletonize(binary_image > 0)\n",
    "    distance = distance_transform_edt(binary_image)\n",
    "    if not np.any(skeleton): return 0\n",
    "    crack_widths_pixels = distance[skeleton] * 2\n",
    "    crack_widths_mm = crack_widths_pixels * pixel_size_mm\n",
    "    return np.max(crack_widths_mm)\n",
    "\n",
    "def get_width_from_image(image_path, pixel_size_mm=0.1):\n",
    "    \"\"\"Reads an image and returns its max crack width.\"\"\"\n",
    "    img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: return None\n",
    "    _, binary_image = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    max_width = crack_width_measure(binary_image, pixel_size_mm)\n",
    "    return max_width\n",
    "\n",
    "def get_widths_from_folder(folder_path, pixel_size_mm=0.1):\n",
    "    \"\"\"Processes a folder of images and returns a dictionary of their widths.\"\"\"\n",
    "    results = {}\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    for filename in tqdm(image_files, desc=f\"Analyzing {Path(folder_path).name}\"):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        max_width = get_width_from_image(image_path, pixel_size_mm)\n",
    "        if max_width is not None:\n",
    "            results[filename] = max_width\n",
    "    return results\n",
    "\n",
    "# ===============================================================\n",
    "# =========== 2. DEFINE FOLDERS AND RUN ANALYSIS ================\n",
    "# ===============================================================\n",
    "\n",
    "# --- Set Your Folders and Calibration Factor Here ---\n",
    "folder_clean = Path(\"Dataset_1000/\")\n",
    "folder_shadowed = Path(\"shadow/\")\n",
    "folder_restored = Path(\"unshadowed_results/\")\n",
    "PIXEL_TO_MM_RATIO = 0.01 # Adjust if needed\n",
    "\n",
    "# --- Run Analysis on Each Folder ---\n",
    "results_clean = get_widths_from_folder(str(folder_clean), pixel_size_mm=PIXEL_TO_MM_RATIO)\n",
    "results_shadowed = get_widths_from_folder(str(folder_shadowed), pixel_size_mm=PIXEL_TO_MM_RATIO)\n",
    "results_restored = get_widths_from_folder(str(folder_restored), pixel_size_mm=PIXEL_TO_MM_RATIO)\n",
    "\n",
    "# --- Combine and Compare Results ---\n",
    "comparison_data = []\n",
    "\n",
    "for clean_filename, clean_width in results_clean.items():\n",
    "    base_name = Path(clean_filename).stem\n",
    "    \n",
    "    # Construct expected filenames\n",
    "    shadow_filename = f\"shadow_{clean_filename}\"\n",
    "    restored_filename_jpg = f\"shadow_{clean_filename}\"\n",
    "    restored_filename_png = f\"shadow_{base_name}.png\" # Assuming GAN saves as PNG\n",
    "    \n",
    "    # Get the corresponding widths from the other dictionaries\n",
    "    shadow_width = results_shadowed.get(shadow_filename)\n",
    "    restored_width = results_restored.get(restored_filename_jpg, results_restored.get(restored_filename_png))\n",
    "\n",
    "    comparison_data.append({\n",
    "        'filename': clean_filename,\n",
    "        'original_width_mm': clean_width,\n",
    "        'shadowed_width_mm': shadow_width,\n",
    "        'restored_width_mm': restored_width\n",
    "    })\n",
    "\n",
    "# Create and save the final DataFrame\n",
    "df_comparison = pd.DataFrame(comparison_data).round(4) # Round to 4 decimals\n",
    "\n",
    "print(\"\\n--- Shadow Width Comparison Report ---\")\n",
    "print(df_comparison.head())\n",
    "\n",
    "output_csv_path = \"shadow.csv\"\n",
    "df_comparison.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\n✅ Final comparison report saved to '{output_csv_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d09c26",
   "metadata": {},
   "source": [
    "Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28450f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================================================\n",
    "# ================= 1. CORE FUNCTIONS ===========================\n",
    "# ===============================================================\n",
    "\n",
    "def crack_width_measure(binary_image, pixel_size_mm=0.1):\n",
    "    \"\"\"Measures the maximum crack width from a binary image.\"\"\"\n",
    "    if np.sum(binary_image) == 0: return 0\n",
    "    skeleton = skeletonize(binary_image > 0)\n",
    "    distance = distance_transform_edt(binary_image)\n",
    "    if not np.any(skeleton): return 0\n",
    "    crack_widths_pixels = distance[skeleton] * 2\n",
    "    crack_widths_mm = crack_widths_pixels * pixel_size_mm\n",
    "    return np.max(crack_widths_mm)\n",
    "\n",
    "def get_width_from_image(image_path, pixel_size_mm=0.1):\n",
    "    \"\"\"Reads an image and returns its max crack width.\"\"\"\n",
    "    img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: return None\n",
    "    _, binary_image = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    max_width = crack_width_measure(binary_image, pixel_size_mm)\n",
    "    return max_width\n",
    "\n",
    "def get_widths_from_folder(folder_path, pixel_size_mm=0.1):\n",
    "    \"\"\"Processes a folder of images and returns a dictionary of their widths.\"\"\"\n",
    "    results = {}\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    for filename in tqdm(image_files, desc=f\"Analyzing {Path(folder_path).name}\"):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        max_width = get_width_from_image(image_path, pixel_size_mm)\n",
    "        if max_width is not None:\n",
    "            results[filename] = max_width\n",
    "    return results\n",
    "\n",
    "# ===============================================================\n",
    "# =========== 2. DEFINE FOLDERS AND RUN ANALYSIS ================\n",
    "# ===============================================================\n",
    "\n",
    "# --- Set Your Folders and Calibration Factor Here ---\n",
    "folder_clean = Path(\"Dataset_1000/\")\n",
    "folder_shadowed = Path(\"blur/\")\n",
    "folder_restored = Path(\"unshadowed_results/\")\n",
    "PIXEL_TO_MM_RATIO = 0.01 # Adjust if needed\n",
    "\n",
    "# --- Run Analysis on Each Folder ---\n",
    "results_clean = get_widths_from_folder(str(folder_clean), pixel_size_mm=PIXEL_TO_MM_RATIO)\n",
    "results_shadowed = get_widths_from_folder(str(folder_shadowed), pixel_size_mm=PIXEL_TO_MM_RATIO)\n",
    "results_restored = get_widths_from_folder(str(folder_restored), pixel_size_mm=PIXEL_TO_MM_RATIO)\n",
    "\n",
    "# --- Combine and Compare Results ---\n",
    "comparison_data = []\n",
    "\n",
    "for clean_filename, clean_width in results_clean.items():\n",
    "    base_name = Path(clean_filename).stem\n",
    "    \n",
    "    # Construct expected filenames\n",
    "    shadow_filename = f\"shadow_{clean_filename}\"\n",
    "    restored_filename_jpg = f\"shadow_{clean_filename}\"\n",
    "    restored_filename_png = f\"shadow_{base_name}.png\" # Assuming GAN saves as PNG\n",
    "    \n",
    "    # Get the corresponding widths from the other dictionaries\n",
    "    shadow_width = results_shadowed.get(shadow_filename)\n",
    "    restored_width = results_restored.get(restored_filename_jpg, results_restored.get(restored_filename_png))\n",
    "\n",
    "    comparison_data.append({\n",
    "        'filename': clean_filename,\n",
    "        'original_width_mm': clean_width,\n",
    "        'shadowed_width_mm': shadow_width,\n",
    "        'restored_width_mm': restored_width\n",
    "    })\n",
    "\n",
    "# Create and save the final DataFrame\n",
    "df_comparison = pd.DataFrame(comparison_data).round(4) # Round to 4 decimals\n",
    "\n",
    "print(\"\\n--- Shadow Width Comparison Report ---\")\n",
    "print(df_comparison.head())\n",
    "\n",
    "output_csv_path = \"shadow_width_comparison_simple.csv\"\n",
    "df_comparison.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\n✅ Final comparison report saved to '{output_csv_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
